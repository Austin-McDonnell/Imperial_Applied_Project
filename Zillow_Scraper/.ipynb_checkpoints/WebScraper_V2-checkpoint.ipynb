{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import re\n",
    "from decimal import *\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.16 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "ua = UserAgent()\n",
    "userAgent = ua.random\n",
    "print(userAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = \"C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/ChromeDriver/chromedriver.exe\"\n",
    "chrome_profile_path = r'user-data-dir=C:\\Users\\austi\\AppData\\Local\\Google\\Chrome\\User Data\\Default'\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(chrome_profile_path)\n",
    "#options.add_argument('headless')\n",
    "options.add_argument(f'--user-agent={userAgent}')\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-popup-blocking\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-impl-side-painting\")\n",
    "options.add_argument(\"--disable-setuid-sandbox\")\n",
    "options.add_argument(\"--disable-seccomp-filter-sandbox\")\n",
    "options.add_argument(\"--disable-single-click-autofill\")\n",
    "options.add_experimental_option(\"excludeSwitches\", ['enable-automation'])\n",
    "options.add_argument(\"window-size=1920,1080\")\n",
    "#plug this into the chrome console: navigator.webdriver -> undefined\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48233\n",
      "\n",
      "CAPTCHA!\n",
      "Manually complete the captcha requirements.\n",
      "Once that's done, if the program was in the middle of scraping (and is still running), it should resume scraping after ~30 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-2b24898e15bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mRunning\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmain\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m '''\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrun_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-111-e9cf1d35adc6>\u001b[0m in \u001b[0;36mrun_main\u001b[1;34m()\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.zillow.com/homes/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mzip_code\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'_rb/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mnavigate_to_website\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-e9cf1d35adc6>\u001b[0m in \u001b[0;36mnavigate_to_website\u001b[1;34m(driver, site, data)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;31m# Check to make sure a captcha page is not displayed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     \u001b[0mcheck_for_captcha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstripPKL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-e9cf1d35adc6>\u001b[0m in \u001b[0;36mcheck_for_captcha\u001b[1;34m(driver, temp_data)\u001b[0m\n\u001b[0;32m    217\u001b[0m               \u001b[1;34m\"Once that's done, if the program was in the middle of scraping \"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m               \"(and is still running), it should resume scraping after ~30 seconds.\")\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[0m_pause_for_captcha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-111-e9cf1d35adc6>\u001b[0m in \u001b[0;36m_pause_for_captcha\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_pause_for_captcha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_element_displayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"captcha-container\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"class\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Running the main function\n",
    "'''\n",
    "run_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original pop-up Window\n",
    "driver.get(r'C:\\Users\\austi\\Documents\\Github_Repos\\Imperial_Applied_Project\\Testing_HTML\\pop_up_window.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zipcode Window\n",
    "driver.get(r'C:\\Users\\austi\\Documents\\Github_Repos\\Imperial_Applied_Project\\Testing_HTML\\48206.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Pop Up Window Test\n",
    "driver.get(r'C:\\Users\\austi\\Documents\\Github_Repos\\Imperial_Applied_Project\\Testing_HTML\\48206_pop_up_window.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vacant Lot Example\n",
    "driver.get(r'C:\\Users\\austi\\Documents\\Github_Repos\\Imperial_Applied_Project\\Testing_HTML\\Vacant_Lot_Example.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No Results Example\n",
    "driver.get(r'C:\\Users\\austi\\Documents\\Github_Repos\\Imperial_Applied_Project\\Testing_HTML\\48205_No_Results_Example.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acceptInsecureCerts': False, 'browserName': 'chrome', 'browserVersion': '76.0.3809.100', 'chrome': {'chromedriverVersion': '75.0.3770.90 (a6dcaf7e3ec6f70a194cc25e8149475c6590e025-refs/branch-heads/3770@{#1003})', 'userDataDir': 'C:\\\\Users\\\\austi\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\\\\Default'}, 'goog:chromeOptions': {'debuggerAddress': 'localhost:59838'}, 'networkConnectionEnabled': False, 'pageLoadStrategy': 'normal', 'platformName': 'windows nt', 'proxy': {}, 'setWindowRect': True, 'strictFileInteractability': False, 'timeouts': {'implicit': 0, 'pageLoad': 300000, 'script': 30000}, 'unhandledPromptBehavior': 'dismiss and notify'}\n"
     ]
    }
   ],
   "source": [
    "print(driver.capabilities)\n",
    "driver.get('https://intoli.com/blog/making-chrome-headless-undetectable/chrome-headless-test.html')\n",
    "#driver.save_screenshot(\"screenshot5.png\")\n",
    "#driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listing_button = driver.find_element_by_id('listing-type').click()\n",
    "#--disable-autofill-keyboard-accessory-view\n",
    "#--disable-physical-keyboard-autocorrect\n",
    "#--disable-single-click-autofill\n",
    "#48126\n",
    "#48201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time_On_Zillow': '335 days', 'Views': '73', 'Saves': '0'} \n",
      "\n",
      "{'Description': 'Rare opportunity...one house and 17 vacant land parcels sold as package deal. Around 2 acres of prime land in up and coming 48215. 18 mostly contiguous parcels on east side of Dickerson.  Sale includes the following parcels: 1526 Dickerson, 1532 Dickerson, 1536 Dickerson, 1546 Dickerson, 1552 Dickerson, 1558 Dickerson, 1564 Dickerson, 1570 Dickerson, 1576 Dickerson (house), 1582 Dickerson, 1586 Dickerson, 1594 Dickerson, 1604 Dickerson, 1610 Dickerson, 1616 Dickerson, 1634 Dickerson, 1640 Dickerson, 1646 Dickerson.  Close proximity to the recently announced 1.6 Billion dollar conversion of Mack Avenue Engine Complex by Fiat Chrysler!'} \n",
      "\n",
      "{'Internet_And_Tv': 'No Data', 'Sunscore': 'Great solar potential\\nSun Number™: 90.74'} \n",
      "\n",
      "{'Price': '383500', 'Address': '1546 Dickerson St, Detroit, MI 48215', 'Zestimate': '', 'Price_Cut': None, 'Price_Cut_Date': None, 'Living_Area': '1.74 acres'} \n",
      "\n",
      "{'Number_Of_Photos': 0} \n",
      "\n",
      "{'Utilities_/_Green_Energy_Details': {'Internet_And_Tv': 'No Data', 'Sunscore': 'Great solar potential\\nSun Number™: 90.74'}, 'Community_And_Neighborhood_Details': {'Region': 'Detroit'}, 'Hoa_And_Financial_Details': {'Has_Hoa_Fee': 'No', 'Tax_Assessed_Value': '$1,400', 'Annual_Tax_Amount': '$9'}, 'Other': {'Mls_Id': '218088384'}} \n",
      "\n",
      "{'latitude': 42.373759, 'longitude': -82.95436} \n",
      "\n",
      "{} \n",
      "\n",
      "{'Schools': {'Southeastern High School': {'Rating': 'NA', 'Grades:': '9-12', 'Distance:': '1.5 mi'}}} \n",
      "\n",
      "{'Walk_Score': {'Description': 'Somewhat Walkable', 'Score': 50}, 'Transit_Score': {'Description': 'Some Transit', 'Score': 38}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_overviewStats(), '\\n')\n",
    "print(get_textDescription(), '\\n')\n",
    "print(get_factsAndFeatures(), '\\n')\n",
    "print(get_homeDetails(), '\\n')\n",
    "print(get_numberOfPhotos(), '\\n')\n",
    "print(get_expandableFactsAndFeatures(), '\\n')\n",
    "print(get_gpsCoordinates(), '\\n')\n",
    "print(get_homeValues(), '\\n')\n",
    "print(get_nearbySchools(), '\\n')\n",
    "print(get_neighborhoodDetails(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "'''\n",
    "Grabbing Data Functions:\n",
    "\n",
    "\n",
    "'''\n",
    "#####################################################\n",
    "def get_gpsCoordinates():\n",
    "    data_dict = {}\n",
    "    string_value = driver.find_element_by_xpath(\"//script[@type='application/ld+json']\").get_attribute('innerHTML')\n",
    "    gps_coords = re.findall('(\\\")(latitude)(\\\")\\:([-+]?[0-9]\\d*(\\.\\d+)?)\\,(\\\")(longitude)(\\\")\\:([-+]?[0-9]\\d*(\\.\\d+)?)', string=string_value)\n",
    "    latitude = gps_coords[0][1]\n",
    "    latitude_num = gps_coords[0][3]\n",
    "    longitude = gps_coords[0][6]\n",
    "    longitude_num = gps_coords[0][8]\n",
    "    data_dict.update({\n",
    "        latitude: float(Decimal(latitude_num)),\n",
    "        longitude: float(Decimal(longitude_num))\n",
    "                     })\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_numberOfPhotos():\n",
    "    data_dict = {}\n",
    "    media = driver.find_element_by_css_selector('ul.media-stream')\n",
    "    # homeValues.find_element_by_xpath(\"//p[contains(@class, 'Text-sc')]\")\n",
    "    num_photos = len(media.find_elements_by_xpath(\"//li[contains(@class, 'media-stream-tile tile-')]\"))\n",
    "    data_dict.update({\n",
    "        'Number_Of_Photos': num_photos\n",
    "    })\n",
    "    return data_dict\n",
    "\n",
    "def get_homeDetails():\n",
    "    data_dict = {}\n",
    "    details = driver.find_element_by_css_selector('div.ds-home-details-chip')\n",
    "    \n",
    "    price = details.find_element_by_xpath(\"//*[@class='ds-price']//span[@class='ds-value']\").get_attribute('innerHTML')\n",
    "    price = re.sub(\"[^\\d\\.]\", \"\", str(price))\n",
    "    \n",
    "    address = driver.find_element_by_css_selector('h1.ds-address-container').text\n",
    "    \n",
    "    living_area = driver.find_element_by_css_selector('span.ds-bed-bath-living-area').text\n",
    "    \n",
    "    price_cut_string = driver.find_elements_by_css_selector('span.ds-price-change.ds-vertical-divider')\n",
    "    if price_cut_string:\n",
    "        price_cut_string = price_cut_string[0].text\n",
    "        price_cut = re.findall('(\\$)([0-9]\\d*(\\.\\d+)?)', price_cut_string)[0][1]\n",
    "        price_cut = float(Decimal(price_cut)*1000)\n",
    "        price_cut_date = re.findall('(\\d+\\/\\d+)', price_cut_string)[0]\n",
    "    else:\n",
    "        price_cut = None\n",
    "        price_cut_date = None\n",
    "    \n",
    "    zestimate = driver.find_elements_by_css_selector('span.ds-estimate-value')\n",
    "    if zestimate:\n",
    "        zestimate = re.sub(\"[^\\d\\.]\", \"\", str(zestimate[0].text))\n",
    "    else:\n",
    "        zestimate = None\n",
    "    \n",
    "    data_dict.update({\n",
    "        'Price': price,\n",
    "        'Address': address,\n",
    "        'Zestimate': zestimate,\n",
    "        'Price_Cut': price_cut,\n",
    "        'Price_Cut_Date': price_cut_date,\n",
    "        'Living_Area': living_area\n",
    "    })\n",
    "    \n",
    "    return data_dict\n",
    "    \n",
    "\n",
    "def get_overviewStats():\n",
    "    data_dict = {}\n",
    "    stats = driver.find_element_by_css_selector('ul.ds-overview-stats')\n",
    "    for stat in stats.find_elements_by_tag_name(\"li\"):\n",
    "        name = stat.find_element_by_css_selector('div.ds-body-small').get_attribute('innerHTML')\n",
    "        name = dict_name_change(name=name)\n",
    "        value = stat.find_element_by_css_selector('div.ds-overview-stat-value').get_attribute('innerHTML')\n",
    "        data_dict.update({name: value})\n",
    "        #sleep(randint(1,5))\n",
    "    return data_dict\n",
    "\n",
    "def get_textDescription():\n",
    "    data_dict = {}\n",
    "    overview = driver.find_element_by_css_selector('div.character-count-text-fold-container')\n",
    "    text_data = overview.find_element_by_tag_name('div').get_attribute('innerHTML')\n",
    "    data_dict.update({'Description': text_data})\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_factsAndFeatures():\n",
    "    data_dict = {}\n",
    "    for fact in driver.find_elements_by_css_selector('li.ds-home-fact-list-item'):\n",
    "        label = fact.find_element_by_css_selector('span.ds-standard-label.ds-home-fact-label').get_attribute('innerHTML')\n",
    "        label = dict_name_change(name=label)\n",
    "        value = fact.find_element_by_css_selector('span.ds-body.ds-home-fact-value').get_attribute('innerHTML')\n",
    "        data_dict.update({label:value})\n",
    "    if not data_dict:\n",
    "        #Run the backup script to handle non-standard data\n",
    "        data_dict = get_backUpFactsAndFeatures()\n",
    "    return data_dict\n",
    "\n",
    "def get_backUpFactsAndFeatures():\n",
    "    data_dict = {}\n",
    "    backup_facts = driver.find_element_by_css_selector('ul.ds-home-fact-list.backup-facts')\n",
    "    for table in backup_facts.find_elements_by_tag_name('table'):\n",
    "        rows = table.find_elements_by_tag_name('tr')\n",
    "        for row in rows:\n",
    "            col = row.find_elements_by_tag_name('td')\n",
    "            data_dict.update({dict_name_change(str(col[0].text)) : str(col[1].text)})\n",
    "    return data_dict\n",
    "    \n",
    "def get_expandableFactsAndFeatures():\n",
    "    data_dict = {}\n",
    "    factsAndFeatures = driver.find_element_by_css_selector('div.ds-home-facts-and-features.reso-facts-features')\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", factsAndFeatures)\n",
    "    time.sleep(5)\n",
    "    button = factsAndFeatures.find_element_by_tag_name('button')\n",
    "    time.sleep(5)\n",
    "    button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    for title in factsAndFeatures.find_elements_by_css_selector('div.ds-body-heading.ds-below-the-fold-header'):\n",
    "        title_name = dict_name_change(title.text)\n",
    "        data_dict.update({\n",
    "            title_name: {}\n",
    "        })\n",
    "        \n",
    "        section = title.find_element_by_xpath('..')\n",
    "        for table in section.find_elements_by_tag_name('table'):\n",
    "            rows = table.find_elements_by_tag_name('tr')\n",
    "            for row in rows:\n",
    "                col = row.find_elements_by_tag_name('td')\n",
    "                data_dict[title_name].update({\n",
    "                    dict_name_change(str(col[0].text)) : str(col[1].text)\n",
    "                })\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "    time.sleep(3)\n",
    "    button.click()\n",
    "    return data_dict\n",
    "\n",
    "def get_homeValues():\n",
    "    data_dict = {}\n",
    "    homeValues = driver.find_element_by_id('ds-home-values')\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", homeValues)\n",
    "    time.sleep(3)\n",
    "    if _is_element_displayed(driver=homeValues, elem_text='message-content', elem_type='class'):\n",
    "        return data_dict\n",
    "    \n",
    "    zestimate_value = homeValues.find_element_by_xpath(\"//p[contains(@class, 'Text-sc')]\").text\n",
    "    print(zestimate_value)\n",
    "    zestimate_value = re.sub(\"[^\\d\\.]\", \"\", zestimate_value)\n",
    "    \n",
    "    sale_range = homeValues.find_element_by_xpath(\"//span[contains(@class, 'Text-sc')]\").text\n",
    "    sale_range = re.sub(\"[^\\d\\.\\-]\", \"\", str(sale_range))\n",
    "    range_numbers = re.findall(\"(\\d+)(\\-)(\\d+)\", sale_range)\n",
    "    upper_range = range_numbers[0][0]\n",
    "    lower_range = range_numbers[0][2]\n",
    "    \n",
    "    data_dict.update({\n",
    "        'Zestimate': zestimate_value,\n",
    "        'Upper_Sale_Estimate': upper_range,\n",
    "        'Lower_Sale_Estimate': lower_range\n",
    "    })\n",
    "    \n",
    "    return data_dict\n",
    "    \n",
    "def get_nearbySchools():\n",
    "    data_dict = {}\n",
    "    schoolList = driver.find_element_by_css_selector('div.ds-nearby-schools-list')\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", schoolList)\n",
    "    time.sleep(5)\n",
    "    data_dict.update({'Schools': {}})\n",
    "    for school in schoolList.find_elements_by_css_selector('div.ds-school-row'):\n",
    "        \n",
    "        school_rating = school.find_element_by_css_selector('div.ds-school-rating').text\n",
    "        school_name = str(school.find_element_by_css_selector('a.ds-school-name.ds-standard-label.notranslate').text)\n",
    "        data_dict['Schools'].update({school_name: {}})\n",
    "        data_dict['Schools'][school_name].update({'Rating': school_rating})\n",
    "        for school_info in school.find_elements_by_css_selector('li.ds-school-info'):\n",
    "            key = school_info.find_element_by_css_selector('span.ds-school-key.ds-body-small').text\n",
    "            value = school_info.find_element_by_css_selector('span.ds-school-value.ds-body-small').text\n",
    "            data_dict['Schools'][school_name].update({dict_name_change(key): value})\n",
    "    \n",
    "    return data_dict\n",
    "        \n",
    "def get_neighborhoodDetails():\n",
    "    for heading in driver.find_elements_by_css_selector('h2.ds-expandable-card-header.ds-section-heading'):\n",
    "        title = str(heading.text)\n",
    "        if title[0:12] == 'Neighborhood':\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", heading)\n",
    "            time.sleep(5)\n",
    "            section = heading.find_element_by_xpath('..')\n",
    "            #print(section.get_attribute('class'))\n",
    "            button_binary = False\n",
    "            if _is_element_displayed(driver=section, elem_text='button', elem_type='tag'):\n",
    "                button_binary = True\n",
    "                button = section.find_element_by_tag_name('button')\n",
    "                button.click()\n",
    "                time.sleep(5)\n",
    "            \n",
    "            def get_scoreSection(element):\n",
    "                data_dict = {}\n",
    "                count = 1\n",
    "                score_section = element\n",
    "                score_section = score_section.find_element_by_css_selector('ul.zsg-list_inline.neighborhood-scores')\n",
    "                for score_name in score_section.find_elements_by_tag_name('li'):\n",
    "                    #print(score_name.find_element_by_tag_name('a').text)\n",
    "                    #print(score_name.find_element_by_tag_name('strong').text)\n",
    "                    #print(f'Score Number: {count} ', score_name.text)\n",
    "                    score_text = re.findall('(\\w+[\\s\\-\\.\\_]\\w+)', score_name.text)\n",
    "                    score_key = dict_name_change(score_text[0])\n",
    "                    score_description = score_text[1]\n",
    "                    score_number = int(re.findall('(\\d+)', score_name.text)[0])\n",
    "                    data_dict.update({\n",
    "                        score_key: {\n",
    "                        'Description': score_description,\n",
    "                        'Score': score_number\n",
    "                        }\n",
    "                    })\n",
    "                return data_dict\n",
    "            break\n",
    "    data_dict = get_scoreSection(element=section)\n",
    "    if button_binary:\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "        time.sleep(3)\n",
    "        button.click()\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "def dict_name_change(name):\n",
    "    name = string.capwords(name)\n",
    "    name = name.replace(' ', '_')\n",
    "    ''.join(e for e in name if e.isalnum())\n",
    "    return name\n",
    "\n",
    "######################################################################################################################\n",
    "def recaptcha_check(data):\n",
    "    input(\"Solve the Recaptcha and then Press Enter to continue...\")\n",
    "    restart_after_captcha(data = data)\n",
    "\n",
    "def restart_after_captcha(data):\n",
    "    input(\"Reset the Zip Code and Page Number; Press Enter to Continue...\")\n",
    "    #photo_cards = driver.find_element_by_css_selector('ul.photo-cards.photo-cards_wow')\n",
    "    data_dict = data\n",
    "    loop_cur_page(data= data_dict)\n",
    "\n",
    "def update_house_dict(main_dict, zpid_value, house_data):\n",
    "    return main_dict[zpid_value].update(house_data)\n",
    "\n",
    "def loop_cur_page(data):\n",
    "    photo_cards = driver.find_element_by_css_selector('ul.photo-cards.photo-cards_wow')\n",
    "    \n",
    "    data_dict = data\n",
    "    for house in photo_cards.find_elements_by_css_selector(\"article\"):\n",
    "        #print(i.find_element_by_css_selector('a').get_attribute('aria-label')\n",
    "        try:\n",
    "            time.sleep(5)\n",
    "            zpid = str(house.get_attribute(\"id\"))\n",
    "            if zpid in data_dict.keys():\n",
    "                continue\n",
    "            data_dict.update({\n",
    "                zpid: {}\n",
    "            })\n",
    "            print(zpid)\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", house)\n",
    "            time.sleep(3)\n",
    "            house.click()\n",
    "            time.sleep(5)\n",
    "            break_val = ''#input(\"Press Enter to continue...\")\n",
    "            if break_val != '':\n",
    "                break\n",
    "            data_dict = get_allHouseData(data_dict[zpid],\n",
    "                                         get_overviewStats(),\n",
    "                                         get_textDescription(),\n",
    "                                         get_factsAndFeatures(),\n",
    "                                         get_homeDetails(),\n",
    "                                         get_numberOfPhotos(),\n",
    "                                         get_expandableFactsAndFeatures(),\n",
    "                                         get_gpsCoordinates(),\n",
    "                                         get_homeValues(),\n",
    "                                         get_nearbySchools(),\n",
    "                                         get_neighborhoodDetails()\n",
    "                                        )\n",
    "            \n",
    "            time.sleep(10)\n",
    "        except NoSuchElementException:\n",
    "            try:\n",
    "                if driver.find_element_by_css_selector('div.captcha-container'):\n",
    "                    check_for_captcha(driver=driver, temp_data= data_dict)\n",
    "                else:\n",
    "                    print('No ZPID Exists Here')\n",
    "            except NoSuchElementException:\n",
    "                print('None')\n",
    "                break\n",
    "        #input(\"Press Enter to continue...\")\n",
    "        driver.find_element_by_css_selector('button.ds-close-lightbox-icon.hc-back-to-list').click()\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_allHouseData(data, *args):\n",
    "    for funct in args:\n",
    "        data.update(funct)\n",
    "    return data\n",
    "\n",
    "def get_wholeZipCode(zipcode, data):\n",
    "    empty_dict = False\n",
    "    if not data:\n",
    "        empty_dict = True\n",
    "    \n",
    "    keep_going = True\n",
    "    \n",
    "    if _is_element_displayed(driver=driver, elem_text='zsg-notification-bar.zsg-content-item', elem_type='class'):\n",
    "        keep_going = False\n",
    "        \n",
    "    while keep_going:\n",
    "        try:\n",
    "            data.update(loop_cur_page(data=data))\n",
    "            time.sleep(5)\n",
    "            \n",
    "        except TimeoutException:\n",
    "            pass\n",
    "        # Check to see if a \"next page\" link exists.\n",
    "        keep_going = _is_element_displayed(driver, \"zsg-pagination-next\",\n",
    "                                           \"class\")\n",
    "        if keep_going:\n",
    "            tries = 5\n",
    "            cover = _is_element_displayed(driver,\n",
    "                                          \"list-loading-message-cover\",\n",
    "                                          \"class\")\n",
    "            while cover and tries > 0:\n",
    "                time.sleep(5)\n",
    "                tries -= 1\n",
    "                cover = _is_element_displayed(driver,\n",
    "                                              \"list-loading-message-cover\",\n",
    "                                              \"class\")\n",
    "                if not cover:\n",
    "                    div = driver.find_element_by_class_name('zsg-pagination-next')\n",
    "                try:\n",
    "                    print('None')\n",
    "                except NoSuchElementException:\n",
    "                    keep_going = False\n",
    "                else:\n",
    "                    try:\n",
    "                        driver.wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"zsg-pagination-next\"))).click()\n",
    "                        time.sleep(3)\n",
    "                        # Check to make sure a captcha page is not displayed.\n",
    "                        check_for_captcha(driver, temp_data=data_dict)\n",
    "                    except TimeoutException:\n",
    "                        keep_going = False\n",
    "            else:\n",
    "                keep_going = False\n",
    "    save_Dictionary(obj=data, name=zipcode)\n",
    "\n",
    "def save_Dictionary(obj, name):\n",
    "    path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/'\n",
    "    with open(path + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def get_tempDictionaryData():\n",
    "    path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/'\n",
    "    fileList = os.listdir(path=path)\n",
    "    if not fileList:\n",
    "        return {}\n",
    "    if fileList[-1] == 'TEMP.pkl':\n",
    "        with open(path + \"TEMP.pkl\", \"rb\") as input_file:\n",
    "            data_dict = pickle.load(input_file)\n",
    "        return data_dict\n",
    "    else:\n",
    "        return {}\n",
    "    \n",
    "def read_zip_code_txt(file_path):\n",
    "    file = open(file_path, 'r')\n",
    "    for line in file:\n",
    "        zipcodes = line.split(',')\n",
    "    zipcodes = [x.strip(' ') for x in zipcodes]\n",
    "    return zipcodes\n",
    "\n",
    "def zillow_zip_code_links(zip_code_list):\n",
    "    links = []\n",
    "    base_link = 'https://www.zillow.com/homes/'\n",
    "    for zip_code in zip_code_list:\n",
    "        links.append(base_link + zip_code + '_rb/')\n",
    "    return links\n",
    "\n",
    "def run_main():\n",
    "    data_dict = get_tempDictionaryData()\n",
    "    \n",
    "    zip_codes_path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/ZipCodes/Detriot_ZipCodes.txt'\n",
    "    file_list = os.listdir(r'C:\\Users\\austi\\Documents\\Github_Repos\\Imperial_Applied_Project\\Detroit\\Saved_Data')\n",
    "    zip_codes = read_zip_code_txt(zip_codes_path)\n",
    "    zip_codes = list(set(zip_codes) - set(file_list))\n",
    "    \n",
    "    for zip_code in zip_codes:\n",
    "        print(zip_code)\n",
    "        link = 'https://www.zillow.com/homes/' + zip_code +'_rb/'\n",
    "        navigate_to_website(driver=driver, site=link, data=data_dict)\n",
    "        time.sleep(randint(5, 10))\n",
    "        \n",
    "        get_wholeZipCode(zipcode=zip_code, data=data_dict)\n",
    "    \n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "def _is_element_displayed(driver, elem_text, elem_type):\n",
    "    if elem_type == \"class\":\n",
    "        try:\n",
    "            out = driver.find_element_by_class_name(elem_text).is_displayed()\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            out = False\n",
    "    elif elem_type == \"css\":\n",
    "        try:\n",
    "            out = driver.find_element_by_css_selector(elem_text).is_displayed()\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            out = False\n",
    "    elif elem_type == 'tag':\n",
    "        try:\n",
    "            out = driver.find_element_by_tag_name(elem_text).is_displayed()\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            out = False\n",
    "    else:\n",
    "        raise ValueError(\"arg 'elem_type' must be either 'class' or 'css'\")\n",
    "    return(out)\n",
    "\n",
    "def _pause_for_captcha(driver):\n",
    "    while True:\n",
    "        time.sleep(30)\n",
    "        if not _is_element_displayed(driver, \"captcha-container\", \"class\"):\n",
    "            break\n",
    "\n",
    "def navigate_to_website(driver, site, data):\n",
    "    driver.get(site)\n",
    "    # Check to make sure a captcha page is not displayed.\n",
    "    check_for_captcha(driver, temp_data=data)\n",
    "\n",
    "def stripPKL(lis):\n",
    "    return([x.replace('.pkl', '') for x in lis])\n",
    "\n",
    "# Check to see if the page is currently stuck on a captcha page. If so, pause\n",
    "# the scraper until user has manually completed the captcha requirements.\n",
    "def check_for_captcha(driver, temp_data):\n",
    "    if _is_element_displayed(driver, \"captcha-container\", \"class\"):\n",
    "        save_Dictionary(obj=temp_data, name='TEMP')\n",
    "        print(\"\\nCAPTCHA!\\n\"\\\n",
    "              \"Manually complete the captcha requirements.\\n\"\\\n",
    "              \"Once that's done, if the program was in the middle of scraping \"\\\n",
    "              \"(and is still running), it should resume scraping after ~30 seconds.\")\n",
    "        _pause_for_captcha(driver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
