{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['48126.html',\n",
       " '48201.html',\n",
       " '48202.html',\n",
       " '48203.html',\n",
       " '48204.html',\n",
       " '48205.html',\n",
       " '48206.html',\n",
       " '48207.html',\n",
       " '48208.html',\n",
       " '48209.html',\n",
       " '48210.html',\n",
       " '48211.html',\n",
       " '48212.html',\n",
       " '48213.html',\n",
       " '48214.html',\n",
       " '48215.html',\n",
       " '48216.html',\n",
       " '48217.html',\n",
       " '48219.html',\n",
       " '48221.html',\n",
       " '48223.html',\n",
       " '48224.html',\n",
       " '48225.html',\n",
       " '48226.html',\n",
       " '48227.html',\n",
       " '48228.html',\n",
       " '48233.html',\n",
       " '48234.html',\n",
       " '48235.html',\n",
       " '48236.html',\n",
       " '48238.html',\n",
       " '48239.html',\n",
       " '48240.html',\n",
       " '48243.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_file_path = r'C:\\Users\\austi\\Documents\\Github_Repos\\Imperial_Applied_Project\\Detroit\\ZipCodes\\HTML_Data'\n",
    "html_files = os.listdir(html_file_path)\n",
    "#TODO: loop through HTML Dir and grab only the HTML files\n",
    "html_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(html_file_path +'\\\\'+ html_files[0]) as fp:\n",
    "    soup = BeautifulSoup(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_link = []\n",
    "for link in soup.body.find_all('div', class_ = 'zsg-photo-card-content zsg-aspect-ratio-content'):\n",
    "    web_link.append('https://www.zillow.com'+ link.find('a').get('href'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.zillow.com/homedetails/5275-Neckel-St-APT-2-Dearborn-MI-48126/2093126182_zpid/'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_link[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-cfc42d89d8eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# gets the home attributes and replaces bad characters for Dictionary; only want home characters though\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#TODO: need to loop through all of the mini bubble templates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'minibubble template hide'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mjson_acceptable_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_acceptable_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# gets the home attributes and replaces bad characters for Dictionary; only want home characters though\n",
    "#TODO: need to loop through all of the mini bubble templates\n",
    "x = str(soup.body.find_all('div', class_ = 'minibubble template hide')[0].contents[0])\n",
    "json_acceptable_string = x.replace(\"\\\\\", \"\")\n",
    "d = json.loads(json_acceptable_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all of the pages worth of data; All of the links for the pages of data\n",
    "links = []\n",
    "for ol in soup.body.find_all('ol'):\n",
    "    for li in ol.find_all('li'):\n",
    "        link = li.contents[0].get('href')\n",
    "        if link != None:\n",
    "            links.append(link)\n",
    "            #TODO: get the max number of pages and set the base link; then loop through the base link until the max number of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/homes/48126_rb/2_p/',\n",
       " '/homes/48126_rb/3_p/',\n",
       " '/homes/48126_rb/4_p/',\n",
       " '/homes/48126_rb/5_p/',\n",
       " '/homes/48126_rb/8_p/',\n",
       " '/homes/48126_rb/2_p/']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def num_homes_in_file(file_list, base_path):\n",
    "    count_list = []\n",
    "    for file_name in file_list:\n",
    "        with open(base_path + '\\\\'+ file_name) as fp:\n",
    "            soup = BeautifulSoup(fp)\n",
    "        fp.close()\n",
    "        count = 0\n",
    "        for house in soup.body.find_all('div', class_ = 'zsg-photo-card-content zsg-aspect-ratio-content'):\n",
    "            count+=1\n",
    "        count_list.append(count)\n",
    "    return count_list\n",
    "# gets the deeper dive link for each home; for more info access\n",
    "count = 0\n",
    "for link in soup.body.find_all('div', class_ = 'zsg-photo-card-content zsg-aspect-ratio-content'):\n",
    "    print(link.find('a').get('href'))\n",
    "    count+= 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_dive(links):\n",
    "    os.chdir\n",
    "    home = 1\n",
    "    for i in links:\n",
    "        urllib.request.urlretrieve(i, \"home_\" + str(home) + \".txt\")\n",
    "        response = urllib.request.urlopen(str(i))\n",
    "        html = BeautifulSoup(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the total number of homes for sale in that zipcode\n",
    "soup.body.find('div', {\"id\": \"map-result-count-message\"}).string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
