{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description:\n",
    "* Can utilize Selenium to acces the Zillow Website and scrape for all of the homes in the Detroit Zip Codes (Post Codes) given\n",
    "* Can also read HTML files saved locally in specified directory tree structure (what was used in this case)\n",
    "1. Pulls the data from the HTML file based on the HTML Structure\n",
    "2. Hashes all of the data into dictionary format and then saves the dictionaries into python PKL formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from IPython.display import Audio\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import re\n",
    "from decimal import *\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os\n",
    "import cProfile\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_locally()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code = '48201'\n",
    "saved_data_html_path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/HTML/'\n",
    "html_files = os.listdir(saved_data_html_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code_list = os.listdir('C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/HTML/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_Files():\n",
    "    \n",
    "    html_files = os.listdir(saved_data_html_path + zip_code)\n",
    "    data_dict = {}\n",
    "    for file in html_files:\n",
    "        #print(file)\n",
    "        temp = file\n",
    "        temp = temp.replace(' ', '_').replace(',', '').replace('#', '')\n",
    "        ''.join(e for e in temp if e.isalnum())\n",
    "return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['48201',\n",
       " '48202',\n",
       " '48203',\n",
       " '48204',\n",
       " '48205',\n",
       " '48206',\n",
       " '48207',\n",
       " '48208',\n",
       " '48209',\n",
       " '48210',\n",
       " '48211',\n",
       " '48212',\n",
       " '48213',\n",
       " '48214',\n",
       " '48215',\n",
       " '48216',\n",
       " '48217',\n",
       " '48219',\n",
       " '48221',\n",
       " '48223',\n",
       " '48224',\n",
       " '48225',\n",
       " '48226',\n",
       " '48227',\n",
       " '48228',\n",
       " '48234',\n",
       " '48235',\n",
       " '48236',\n",
       " '48238',\n",
       " '48239',\n",
       " '48240']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_zip_code_path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/HTML/'\n",
    "html_zip_code_list = os.listdir(html_zip_code_path)\n",
    "html_zip_code_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_file_name(folder_path):\n",
    "    file_list = os.listdir(folder_path)\n",
    "    for file in file_list:\n",
    "        temp = file\n",
    "        temp = temp.replace(' ', '_').replace(',', '').replace('#', '')\n",
    "        ''.join(e for e in temp if e.isalnum())\n",
    "        os.rename(folder_path + file, folder_path + temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_removal(folder_path):\n",
    "    file_list = os.listdir(folder_path)\n",
    "    remove_file_pattern = \"(\\.DS_Store)|(\\._.+)\"\n",
    "    for file in file_list:\n",
    "        selected = re.findall(pattern=remove_file_pattern, string=file)\n",
    "        if not selected:\n",
    "            continue\n",
    "        clean_string = ''.join(selected[0])\n",
    "        os.remove(folder_path + clean_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.62 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "ua = UserAgent()\n",
    "userAgent = ua.random\n",
    "print(userAgent)\n",
    "chrome_driver_path = \"C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/ChromeDriver/chromedriver.exe\"\n",
    "chrome_profile_path = r'user-data-dir=C:\\Users\\austi\\AppData\\Local\\Google\\Chrome\\User Data\\Default'\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(chrome_profile_path)\n",
    "options.add_argument(f'--user-agent={userAgent}')\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-popup-blocking\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-impl-side-painting\")\n",
    "options.add_argument(\"--disable-setuid-sandbox\")\n",
    "options.add_argument(\"--disable-seccomp-filter-sandbox\")\n",
    "options.add_argument(\"--disable-single-click-autofill\")\n",
    "options.add_experimental_option(\"excludeSwitches\", ['enable-automation'])\n",
    "options.add_argument(\"window-size=1920,1080\")\n",
    "#plug this into the chrome console: navigator.webdriver -> undefined\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/HTML/48126/House_1.html'):\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/HTML/48204/8606_Ohio_St_Detroit_MI_48204___MLS_218091534___Zillow.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/HTML/48204/8606_Ohio_St_Detroit_MI_48204___MLS_218091534___Zillow.htm'\n",
    "with open(path, encoding='utf8') as fp:\n",
    "    soup = BeautifulSoup(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "forclosed_path = 'C:/Users/austi/Downloads/forclosed_test.html'\n",
    "with open(forclosed_path, encoding='utf8') as fp:\n",
    "    forclosed_soup = BeautifulSoup(fp)\n",
    "fp.close()\n",
    "\n",
    "test_path = r'C:\\Users\\austi\\Documents\\Github_Repos\\Imperial_Applied_Project\\Testing_HTML\\pop_up_window.html'\n",
    "with open(test_path, encoding='utf8') as fp:\n",
    "    test_soup = BeautifulSoup(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/HTML/48201/104_Edmund_Pl_APT_2_Detroit_MI_48201___Zillow.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for heading in driver.find_elements_by_css_selector('h2.ds-expandable-card-header.ds-section-heading'):\n",
    "    title = str(heading.text)\n",
    "    if title[0:12] == 'Neighborhood':\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", heading)\n",
    "        section = heading.find_element_by_xpath('..')\n",
    "        if _is_element_displayed(driver=section, elem_text='button', elem_type='tag'):\n",
    "            button = section.find_element_by_tag_name('button')\n",
    "            button.click()\n",
    "            break\n",
    "soup = BeautifulSoup(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r'C:\\Users\\austi\\Documents\\Github_Repos\\Imperial_Applied_Project\\Testing_HTML\\pop_up_window.html'\n",
    "with open(test_path, encoding='utf8') as fp:\n",
    "    driver = BeautifulSoup(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2096667469_zpid\n"
     ]
    }
   ],
   "source": [
    "#print(get_zpid(soup))\n",
    "#print(get_overviewStats(soup))\n",
    "#print(get_textDescription(soup), '\\n')\n",
    "#print(get_factsAndFeatures(soup), '\\n')\n",
    "#print(get_homeDetails(soup), '\\n')\n",
    "#print(get_numberOfPhotos(soup), '\\n')\n",
    "#print(get_expandableFactsAndFeatures(soup), '\\n')\n",
    "#print(get_gpsCoordinates(soup), '\\n')\n",
    "print(get_commuteScores(soup), '\\n')\n",
    "#print(get_homeValues(soup), '\\n')\n",
    "#print(get_nearbySchools(soup), '\\n')\n",
    "#print(get_neighborhoodDetails(driver), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zpid(driver):\n",
    "    try:\n",
    "        #string_value = driver.find_element_by_xpath(\"//script[@type='application/ld+json']\").get_attribute('innerHTML')\n",
    "        #string_value = driver.find_element_by_css_selector('script.application/ld+json').text\n",
    "        string_value = driver.body.find(\"script\", {\"type\": 'application/ld+json'}).get_text()\n",
    "        url_string = json.loads(string_value)['url']\n",
    "        zpid = re.findall(\"(\\d+_zpid)\", url_string)\n",
    "        if not zpid:\n",
    "            print('NO ZPID')\n",
    "        return zpid[0]\n",
    "        \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        value = driver.body.find(\"div\", {\"type\": 'application/ld+json'}).get_text()\n",
    "        #value = driver.find_element_by_css_selector('div.zsg-notification-bar')\n",
    "        if value.get_text() == 'There was an error retrieving some of the data for this home. Click here to try again.':\n",
    "            raise ValueError('The Link Does Not Work')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "'''\n",
    "Grabbing Data Functions:\n",
    "\n",
    "\n",
    "'''\n",
    "#####################################################\n",
    "def run_locally():\n",
    "    \n",
    "    #driver = setup_driver()\n",
    "    #time.sleep(3)\n",
    "    \n",
    "    data_dict_path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/Test_Data_Dict/'\n",
    "    #saved_data_html_path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/HTML/'\n",
    "    os.chdir(data_dict_path)\n",
    "    #zip_code_text_file_path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/ZipCodes/Detriot_ZipCodes.txt'\n",
    "    #zip_codes_text_file_list = read_zip_code_txt(zip_code_text_file_path)\n",
    "    \n",
    "    #loop_zip_code(driver, zip_codes_text_file_list)\n",
    "    #driver = driver\n",
    "    html_path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/HTML/'\n",
    "    #data_dict_path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/Data_Dict/'\n",
    "    \n",
    "    for zip_code in os.listdir(html_path):\n",
    "        print(zip_code)\n",
    "        completed_dict = {}\n",
    "        data_dict = {}\n",
    "        loaded_old_dict = False\n",
    "        #count = 1\n",
    "        if os.path.exists(data_dict_path+ zip_code + '.pkl'):\n",
    "            data_dict = load_Dictionary(data_dict_path, file_name=zip_code)\n",
    "            loaded_old_dict = True\n",
    "        if os.path.exists(data_dict_path + 'Completed_Files.pkl'):\n",
    "            completed_dict = load_Dictionary(data_dict_path, 'Completed_Files')\n",
    "        \n",
    "        for file in os.listdir(html_path + zip_code):\n",
    "            \n",
    "            if (zip_code + '_' + file) in completed_dict.keys():\n",
    "                #print(f'Already processed and Saved: {file}')\n",
    "                continue\n",
    "            \n",
    "            print(f'Scraping... {file}')\n",
    "            with open(html_path + zip_code +'/'+ file, encoding='utf8') as fp:\n",
    "                soup = BeautifulSoup(fp)\n",
    "            fp.close()\n",
    "            #soup = BeautifulSoup(driver.page_source)\n",
    "            #time.sleep(2)\n",
    "            \n",
    "            zpid = get_zpid(soup)\n",
    "            \n",
    "            if (zpid in data_dict.keys()) and (loaded_old_dict == False):\n",
    "                print(f'Check Keys: {zpid}, file: {file}')\n",
    "                #input('Enter something to continue: ')\n",
    "            if (zpid in data_dict.keys()) and (loaded_old_dict == True):\n",
    "                print(f'Already Scraped, {zpid} size: {len(data_dict[zpid].keys())}')\n",
    "                completed_dict.update({zip_code + '_' + file: None})\n",
    "                save_Dictionary(obj=completed_dict, name='Completed_Files')\n",
    "                #driver = driver.close()\n",
    "                continue\n",
    "            \n",
    "            data_dict.update({zpid: {}})\n",
    "            \n",
    "            data_dict[zpid] = get_allHouseData(\n",
    "            data_dict[zpid],\n",
    "            get_overviewStats(soup),\n",
    "            get_textDescription(soup),\n",
    "            get_factsAndFeatures(soup),\n",
    "            get_homeDetails(soup),\n",
    "            get_numberOfPhotos(soup),\n",
    "            get_expandableFactsAndFeatures(soup),\n",
    "            get_gpsCoordinates(soup),\n",
    "            #get_homeValues(soup),\n",
    "            get_nearbySchools(soup),\n",
    "            #get_commuteScores(soup)\n",
    "            )\n",
    "            completed_dict.update({zip_code + '_' + file: None})\n",
    "            save_Dictionary(obj=data_dict, name=zip_code)\n",
    "            save_Dictionary(obj=completed_dict, name='Completed_Files')\n",
    "            #count += 1\n",
    "\n",
    "        #print(data_dict)\n",
    "        \n",
    "    save_Dictionary(data_dict, zip_code)\n",
    "\n",
    "def play_sound(self, etype, value, tb, tb_offset=None):\n",
    "    self.showtraceback((etype, value, tb), tb_offset=tb_offset)\n",
    "    display(Audio('C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Zillow_Scraper/CongaGroove.wav', autoplay=True))\n",
    "\n",
    "def load_Dictionary(path, file_name):\n",
    "    with open(path + str(file_name) + \".pkl\", \"rb\") as input_file:\n",
    "        data_dict = pickle.load(input_file)\n",
    "    return data_dict\n",
    "def check_forclosure(driver):\n",
    "    price = driver.find_element_by_css_selector('h3.ds-price').text\n",
    "    if price == 'Price Unknown':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def setup_driver():\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    chrome_driver_path = \"C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/ChromeDriver/chromedriver.exe\"\n",
    "    chrome_profile_path = r'user-data-dir=C:\\Users\\austi\\AppData\\Local\\Google\\Chrome\\User Data\\Default'\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(chrome_profile_path)\n",
    "    options.add_argument('headless')\n",
    "    options.add_argument(f'--user-agent={userAgent}')\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--disable-popup-blocking\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-impl-side-painting\")\n",
    "    options.add_argument(\"--disable-setuid-sandbox\")\n",
    "    options.add_argument(\"--disable-seccomp-filter-sandbox\")\n",
    "    options.add_argument(\"--disable-single-click-autofill\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", ['enable-automation'])\n",
    "    #options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"window-size=1920,1080\")\n",
    "    #plug this into the chrome console: navigator.webdriver -> undefined\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path=chrome_driver_path, options=options)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "get_ipython().set_custom_exc((Exception,), play_sound)\n",
    "def get_gpsCoordinates(driver):\n",
    "    data_dict = {}\n",
    "    #string_value = driver.find_element_by_xpath(\"//script[@type='application/ld+json']\").get_attribute('innerHTML')\n",
    "    #gps_coords = re.findall('(\\\")(latitude)(\\\")\\:([-+]?[0-9]\\d*(\\.\\d+)?)\\,(\\\")(longitude)(\\\")\\:([-+]?[0-9]\\d*(\\.\\d+)?)', string=string_value)\n",
    "    #latitude = gps_coords[0][1]\n",
    "    #latitude_num = gps_coords[0][3]\n",
    "    #longitude = gps_coords[0][6]\n",
    "    #longitude_num = gps_coords[0][8]\n",
    "    string_value = driver.body.find(\"script\", {\"type\": 'application/ld+json'}).get_text()\n",
    "    \n",
    "    data_dict.update({\n",
    "        'Latitude': json.loads(string_value)['geo']['latitude'],\n",
    "        'Longitude': json.loads(string_value)['geo']['longitude']\n",
    "                     })\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_zpid(driver):\n",
    "    try:\n",
    "        #string_value = driver.find_element_by_xpath(\"//script[@type='application/ld+json']\").get_attribute('innerHTML')\n",
    "        #string_value = driver.find_element_by_css_selector('script.application/ld+json').text\n",
    "        string_value = driver.body.find(\"script\", {\"type\": 'application/ld+json'}).get_text()\n",
    "        url_string = json.loads(string_value)['url']\n",
    "        zpid = re.findall(\"(\\d+_zpid)\", url_string)\n",
    "        if not zpid:\n",
    "            print('NO ZPID')\n",
    "        return zpid[0]\n",
    "        \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        value = driver.body.find(\"div\", {\"type\": 'application/ld+json'}).get_text()\n",
    "        #value = driver.find_element_by_css_selector('div.zsg-notification-bar')\n",
    "        if value.get_text() == 'There was an error retrieving some of the data for this home. Click here to try again.':\n",
    "            raise ValueError('The Link Does Not Work')\n",
    "\n",
    "def get_numberOfPhotos(driver):\n",
    "    data_dict = {}\n",
    "    #media = driver.find_element_by_css_selector('ul.media-stream')\n",
    "    num_photos = len(driver.body.find('ul', {'class': 'media-stream'}))\n",
    "    # homeValues.find_element_by_xpath(\"//p[contains(@class, 'Text-sc')]\")\n",
    "    #num_photos = len(media.find_elements_by_xpath(\"//li[contains(@class, 'media-stream-tile tile-')]\"))\n",
    "    data_dict.update({\n",
    "        'Number_Of_Photos': num_photos\n",
    "    })\n",
    "    return data_dict\n",
    "\n",
    "def get_homeDetails(driver):\n",
    "    data_dict = {}\n",
    "    #details = driver.find_element_by_css_selector('div.ds-home-details-chip')\n",
    "    price = driver.body.find('h3', {'class': 'ds-price'}).get_text()\n",
    "    if price != 'Price Unknown':\n",
    "        price = re.sub(\"[^\\d\\.]\", \"\", str(price))\n",
    "    \n",
    "    address = driver.body.find('h1', {'class': 'ds-address-container'}).get_text()#driver.find_element_by_css_selector('h1.ds-address-container').text\n",
    "    \n",
    "    living_area = driver.body.find('span', {'class': 'ds-bed-bath-living-area'}).get_text()#driver.find_element_by_css_selector('span.ds-bed-bath-living-area').text\n",
    "    \n",
    "    price_cut_string = driver.body.find('span', {'class': 'ds-price-change ds-vertical-divider'})#.find_elements_by_css_selector('span.ds-price-change.ds-vertical-divider')\n",
    "    if price_cut_string != None:\n",
    "        price_cut_string = price_cut_string.get_text()\n",
    "        price_cut = re.findall('(\\$)([0-9]\\d*(\\.\\d+)?)', price_cut_string)[0][1]\n",
    "        price_cut = float(Decimal(price_cut)*1000)\n",
    "        price_cut_date = re.findall('(\\d+\\/\\d+)', price_cut_string)[0]\n",
    "    else:\n",
    "        price_cut = None\n",
    "        price_cut_date = None\n",
    "    \n",
    "    zestimate = driver.body.find('span', {'class': 'ds-estimate'})#driver.find_elements_by_css_selector('span.ds-estimate-value')\n",
    "    if zestimate:\n",
    "        zestimate = re.sub(\"[^\\d\\.]\", \"\", zestimate.get_text())\n",
    "    else:\n",
    "        zestimate = None\n",
    "    \n",
    "    data_dict.update({\n",
    "        'Price': price,\n",
    "        'Address': address,\n",
    "        'Zestimate': zestimate,\n",
    "        'Price_Cut': price_cut,\n",
    "        'Price_Cut_Date': price_cut_date,\n",
    "        'Living_Area': living_area\n",
    "    })\n",
    "    \n",
    "    return data_dict\n",
    "    \n",
    "\n",
    "def get_overviewStats(driver):\n",
    "    data_dict = {}\n",
    "    stats = driver.body.find('ul', {'class': 'ds-overview-stats'})#driver.find_element_by_css_selector('ul.ds-overview-stats')\n",
    "    for stat in stats.find_all(\"li\"):\n",
    "        name = stat.find('div', {'class': 'ds-body-small'}).get_text()#find_element_by_css_selector('div.ds-body-small').text#get_attribute('innerHTML')\n",
    "        name = dict_name_change(name=name)\n",
    "        value = stat.find('div', {'class': 'ds-overview-stat-value'}).get_text()#find_element_by_css_selector('div.ds-overview-stat-value').text#get_attribute('innerHTML')\n",
    "        data_dict.update({name: value})\n",
    "        #sleep(randint(1,5))\n",
    "    return data_dict\n",
    "\n",
    "def get_textDescription(driver):\n",
    "    data_dict = {}\n",
    "    #overview = driver.body.find('div', {'class': 'character-count-text-fold-container'})#driver.find_element_by_css_selector('div.character-count-text-fold-container')\n",
    "    text_data = driver.body.find('div', {'class': 'character-count-text-fold-container'}).get_text()\n",
    "    data_dict.update({'Description': text_data})\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_factsAndFeatures(driver):\n",
    "    data_dict = {}\n",
    "    fact_list = driver.body.find('ul', {'class': 'ds-home-fact-list backup-facts'})\n",
    "    if fact_list != None:\n",
    "        #Run the backup script to handle non-standard data\n",
    "        return get_backUpFactsAndFeatures(driver)\n",
    "    else:\n",
    "        fact_list = driver.body.find('ul', {'class': 'ds-home-fact-list'})\n",
    "        for fact in fact_list.find_all('li'):\n",
    "            label = fact.find('span', {'class', 'ds-standard-label ds-home-fact-label'}).get_text()#\n",
    "            label = dict_name_change(name=label)\n",
    "            value = fact.find('span', {'class', 'ds-body ds-home-fact-value'}).get_text()\n",
    "            data_dict.update({label:value})\n",
    "        return data_dict\n",
    "\n",
    "def get_backUpFactsAndFeatures(driver):\n",
    "    data_dict = {}\n",
    "    backup_facts = driver.body.find('ul', {'class': 'ds-home-fact-list backup-facts'}).next_element\n",
    "    if not backup_facts:\n",
    "        return data_dict\n",
    "    for table in backup_facts.find_all('table'):#.find_elements_by_tag_name('table'):\n",
    "        #print(table, '\\n')\n",
    "        for row in table.find_all('tr'):\n",
    "            #print(row)\n",
    "            cols = row.find_all('td')\n",
    "            data_dict.update({dict_name_change(str(cols[0].get_text())) : str(cols[1].get_text())})\n",
    "    return data_dict\n",
    "    \n",
    "def get_expandableFactsAndFeatures(driver):\n",
    "    data_dict = {}\n",
    "    factsAndFeatures = driver.body.find('div', {'class': 'ds-home-facts-and-features reso-facts-features'})\n",
    "    for title in factsAndFeatures.find_all('div', {'class': 'ds-body-heading ds-below-the-fold-header'}):\n",
    "        title_name = dict_name_change(title.get_text())\n",
    "        data_dict.update({\n",
    "            title_name: {}\n",
    "        })\n",
    "        section = title.previous_element()[1]\n",
    "        tables = section.find_all('table')\n",
    "        for table in tables:\n",
    "            for row in table.find_all('tr'):\n",
    "                cols = row.find_all('td')\n",
    "                data_dict[title_name].update({\n",
    "                dict_name_change(str(cols[0].get_text())) : str(cols[1].get_text())\n",
    "                })\n",
    "    return data_dict\n",
    "\n",
    "def get_homeValues(driver):\n",
    "    data_dict = {}\n",
    "    homeValues = driver.find('div', {'id': 'ds-home-values'})\n",
    "    if homeValues.find('div', {'class': 'message-content'}) != None:\n",
    "        return data_dict\n",
    "    \n",
    "    zestimate_value = homeValues.find('p')\n",
    "    if zestimate_value != None:\n",
    "        zestimate_value = re.sub(\"[^\\d\\.]\", \"\", zestimate_value.get_text())\n",
    "    \n",
    "    #sale_range = homeValues.find_element_by_xpath(\"//span[contains(@class, 'Text-sc')]\").text\n",
    "    #sale_range = re.sub(\"[^\\d\\.\\-]\", \"\", str(sale_range))\n",
    "    #range_numbers = re.findall(\"(\\d+)(\\-)(\\d+)\", sale_range)\n",
    "    #upper_range = range_numbers[0][0]\n",
    "    #lower_range = range_numbers[0][2]\n",
    "    \n",
    "    data_dict.update({\n",
    "        'Zestimate': zestimate_value,\n",
    "        #'Upper_Sale_Estimate': upper_range,\n",
    "        #'Lower_Sale_Estimate': lower_range\n",
    "    })\n",
    "    \n",
    "    return data_dict\n",
    "    \n",
    "def get_nearbySchools(driver):\n",
    "    data_dict = {}\n",
    "    data_dict.update({'Schools': {}})\n",
    "    if driver.body.find('div', {'class':'ds-no-school-item ds-standard-label'}) != None:\n",
    "        return data_dict\n",
    "    \n",
    "    schoolList = driver.body.find('div', {'class':'ds-nearby-schools-list'})\n",
    "    for school in schoolList.find_all('div', {'class':'ds-school-row'}):\n",
    "        \n",
    "        school_rating = school.find('div', {'class':'ds-school-rating'}).get_text()\n",
    "        school_name = str(school.find('a', {'class':'ds-school-name ds-standard-label notranslate'}).get_text())\n",
    "        data_dict['Schools'].update({school_name: {}})\n",
    "        data_dict['Schools'][school_name].update({'Rating': school_rating})\n",
    "        for school_info in school.find_all('li', {'class':'ds-school-info'}):\n",
    "            key = school_info.find('span', {'class':'ds-school-key ds-body-small'}).get_text()\n",
    "            value = school_info.find('span', {'class':'ds-school-value ds-body-small'}).get_text()\n",
    "            data_dict['Schools'][school_name].update({dict_name_change(key): value})\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_commuteScores(driver):\n",
    "    data_dict = {}\n",
    "    score_section = driver.body.find('ul', {'class', 'zsg-list_inline neighborhood-scores'})\n",
    "    for score_name in score_section.find_all('li'):\n",
    "        #print(score_name)\n",
    "        score_text = re.findall('(\\w+[\\s\\-\\.\\_]\\w+)', score_name.get_text())\n",
    "        score_key = dict_name_change(score_text[0])\n",
    "        score_description = score_text[1]\n",
    "        score_number = int(re.findall('(\\d+)', score_name.get_text())[0])\n",
    "        data_dict.update({\n",
    "                    score_key: {\n",
    "                    'Description': score_description,\n",
    "                    'Score': score_number\n",
    "                    }\n",
    "        })\n",
    "        \n",
    "    return data_dict\n",
    "        \n",
    "def get_neighborhoodDetails(driver):\n",
    "    def get_scoreSection(element):\n",
    "        data_dict = {}\n",
    "        if element == None:\n",
    "            return data_dict\n",
    "        count = 1\n",
    "        score_section = element\n",
    "        score_section = score_section.find_element_by_css_selector('ul.zsg-list_inline.neighborhood-scores')\n",
    "        for score_name in score_section.find_elements_by_tag_name('li'):\n",
    "            #print(score_name.find_element_by_tag_name('a').text)\n",
    "            #print(score_name.find_element_by_tag_name('strong').text)\n",
    "            #print(f'Score Number: {count} ', score_name.text)\n",
    "            score_text = re.findall('(\\w+[\\s\\-\\.\\_]\\w+)', score_name.text)\n",
    "            score_key = dict_name_change(score_text[0])\n",
    "            score_description = score_text[1]\n",
    "            score_number = int(re.findall('(\\d+)', score_name.text)[0])\n",
    "            data_dict.update({\n",
    "                score_key: {\n",
    "                'Description': score_description,\n",
    "                'Score': score_number\n",
    "                }\n",
    "            })\n",
    "        return data_dict\n",
    "    for heading in driver.find_elements_by_css_selector('h2.ds-expandable-card-header.ds-section-heading'):\n",
    "        title = str(heading.text)\n",
    "        if title[0:12] == 'Neighborhood':\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", heading)\n",
    "            time.sleep(3)\n",
    "            section = heading.find_element_by_xpath('..')\n",
    "            #print(section.get_attribute('class'))\n",
    "            button_binary = False\n",
    "            if _is_element_displayed(driver=section, elem_text='button', elem_type='tag'):\n",
    "                button_binary = True\n",
    "                button = section.find_element_by_tag_name('button')\n",
    "                button.click()\n",
    "                time.sleep(3)\n",
    "            break\n",
    "        else:\n",
    "            section = None\n",
    "            button_binary = False\n",
    "    data_dict = get_scoreSection(element=section)\n",
    "    if button_binary:\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "        time.sleep(2)\n",
    "        button.click()\n",
    "    return data_dict\n",
    "\n",
    "#####################################################################################################################\n",
    "def dict_name_change(name):\n",
    "    name = string.capwords(name)\n",
    "    name = name.replace(' ', '_')\n",
    "    ''.join(e for e in name if e.isalnum())\n",
    "    return name\n",
    "\n",
    "######################################################################################################################\n",
    "def recaptcha_check(data):\n",
    "    input(\"Solve the Recaptcha and then Press Enter to continue...\")\n",
    "    restart_after_captcha(data = data)\n",
    "\n",
    "def restart_after_captcha(data):\n",
    "    input(\"Reset the Zip Code and Page Number; Press Enter to Continue...\")\n",
    "    #photo_cards = driver.find_element_by_css_selector('ul.photo-cards.photo-cards_wow')\n",
    "    data_dict = data\n",
    "    loop_cur_page(data= data_dict)\n",
    "\n",
    "def update_house_dict(main_dict, zpid_value, house_data):\n",
    "    return main_dict[zpid_value].update(house_data)\n",
    "\n",
    "def loop_cur_page(driver, data):\n",
    "    photo_cards = driver.find_element_by_css_selector('ul.photo-cards.photo-cards_wow')\n",
    "    \n",
    "    data_dict = data\n",
    "    for house in photo_cards.find_elements_by_css_selector(\"article\"):\n",
    "        #print(i.find_element_by_css_selector('a').get_attribute('aria-label')\n",
    "        try:\n",
    "            time.sleep(3)\n",
    "            zpid = str(house.get_attribute(\"id\"))\n",
    "            if zpid in data_dict.keys():\n",
    "                continue\n",
    "            data_dict.update({\n",
    "                zpid: {}\n",
    "            })\n",
    "            print(zpid)\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", house)\n",
    "            time.sleep(3)\n",
    "            house.click()\n",
    "            time.sleep(2)\n",
    "            break_val = ''#input(\"Press Enter to continue...\")\n",
    "            if break_val != '':\n",
    "                break\n",
    "            data_dict = get_allHouseData(data_dict[zpid],\n",
    "                                         get_overviewStats(driver),\n",
    "                                         get_textDescription(driver),\n",
    "                                         get_factsAndFeatures(driver),\n",
    "                                         get_homeDetails(driver),\n",
    "                                         get_numberOfPhotos(driver),\n",
    "                                         get_expandableFactsAndFeatures(driver),\n",
    "                                         get_gpsCoordinates(driver),\n",
    "                                         get_homeValues(driver),\n",
    "                                         get_nearbySchools(driver),\n",
    "                                         get_neighborhoodDetails(driver)\n",
    "                                        )\n",
    "            \n",
    "            time.sleep(10)\n",
    "        except NoSuchElementException:\n",
    "            try:\n",
    "                if driver.find_element_by_css_selector('div.captcha-container'):\n",
    "                    check_for_captcha(driver=driver, temp_data= data_dict)\n",
    "                else:\n",
    "                    print('No ZPID Exists Here')\n",
    "            except NoSuchElementException:\n",
    "                print('None')\n",
    "                break\n",
    "        #input(\"Press Enter to continue...\")\n",
    "        driver.find_element_by_css_selector('button.ds-close-lightbox-icon.hc-back-to-list').click()\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_allHouseData(*args):\n",
    "    data = args[0]\n",
    "    for funct in args[1:]:\n",
    "        data.update(funct)\n",
    "    return data\n",
    "\n",
    "def get_wholeZipCode(driver, zipcode, data):\n",
    "    empty_dict = False\n",
    "    if not data:\n",
    "        empty_dict = True\n",
    "    \n",
    "    keep_going = True\n",
    "    \n",
    "    if _is_element_displayed(driver=driver, elem_text='zsg-notification-bar.zsg-content-item', elem_type='class'):\n",
    "        keep_going = False\n",
    "        \n",
    "    while keep_going:\n",
    "        try:\n",
    "            data.update(loop_cur_page(driver=driver, data=data))\n",
    "            time.sleep(5)\n",
    "            \n",
    "        except TimeoutException:\n",
    "            pass\n",
    "        # Check to see if a \"next page\" link exists.\n",
    "        keep_going = _is_element_displayed(driver, \"zsg-pagination-next\",\n",
    "                                           \"class\")\n",
    "        if keep_going:\n",
    "            tries = 5\n",
    "            cover = _is_element_displayed(driver,\n",
    "                                          \"list-loading-message-cover\",\n",
    "                                          \"class\")\n",
    "            while cover and tries > 0:\n",
    "                time.sleep(5)\n",
    "                tries -= 1\n",
    "                cover = _is_element_displayed(driver,\n",
    "                                              \"list-loading-message-cover\",\n",
    "                                              \"class\")\n",
    "                if not cover:\n",
    "                    div = driver.find_element_by_class_name('zsg-pagination-next')\n",
    "                try:\n",
    "                    print('None')\n",
    "                except NoSuchElementException:\n",
    "                    keep_going = False\n",
    "                else:\n",
    "                    try:\n",
    "                        driver.wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"zsg-pagination-next\"))).click()\n",
    "                        time.sleep(3)\n",
    "                        # Check to make sure a captcha page is not displayed.\n",
    "                        check_for_captcha(driver, temp_data=data_dict)\n",
    "                    except TimeoutException:\n",
    "                        keep_going = False\n",
    "            else:\n",
    "                keep_going = False\n",
    "    save_Dictionary(obj=data, name=zipcode)\n",
    "\n",
    "def save_Dictionary(obj, name):\n",
    "    path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/Test_Data_Dict/'\n",
    "    with open(path + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def get_tempDictionaryData():\n",
    "    path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/Saved_Data/'\n",
    "    fileList = os.listdir(path=path)\n",
    "    if not fileList:\n",
    "        return {}\n",
    "    if fileList[-1] == 'TEMP.pkl':\n",
    "        with open(path + \"TEMP.pkl\", \"rb\") as input_file:\n",
    "            data_dict = pickle.load(input_file)\n",
    "        return data_dict\n",
    "    else:\n",
    "        return {}\n",
    "    \n",
    "def read_zip_code_txt(file_path):\n",
    "    file = open(file_path, 'r')\n",
    "    for line in file:\n",
    "        zipcodes = line.split(',')\n",
    "    zipcodes = [x.strip(' ') for x in zipcodes]\n",
    "    return zipcodes\n",
    "\n",
    "def zillow_zip_code_links(zip_code_list):\n",
    "    links = []\n",
    "    base_link = 'https://www.zillow.com/homes/'\n",
    "    for zip_code in zip_code_list:\n",
    "        links.append(base_link + zip_code + '_rb/')\n",
    "    return links\n",
    "\n",
    "def run_main(driver):\n",
    "    data_dict = get_tempDictionaryData()\n",
    "    \n",
    "    #zip_codes_path = 'C:/Users/austi/Documents/Github_Repos/Imperial_Applied_Project/Detroit/ZipCodes/Detriot_ZipCodes.txt'\n",
    "    #file_list = os.listdir(r'C:\\Users\\austi\\Documents\\Github_Repos\\Imperial_Applied_Project\\Detroit\\Saved_Data')\n",
    "    #zip_codes = read_zip_code_txt(zip_codes_path)\n",
    "    #zip_codes = list(set(zip_codes) - set(file_list))\n",
    "    \n",
    "    #for zip_code in zip_codes:\n",
    "        #print(zip_code)\n",
    "        #link = 'https://www.zillow.com/homes/' + zip_code +'_rb/'\n",
    "        #time.sleep(3)\n",
    "        #navigate_to_website(driver=driver, site=link, data=data_dict)\n",
    "        #time.sleep(randint(5, 10))\n",
    "    zip_code = input('Enter a Zip Code: ')    \n",
    "    get_wholeZipCode(driver=driver, zipcode=zip_code, data=data_dict)\n",
    "    \n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "def _is_element_displayed(driver, elem_text, elem_type):\n",
    "    if elem_type == \"class\":\n",
    "        try:\n",
    "            out = driver.find_element_by_class_name(elem_text).is_displayed()\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            out = False\n",
    "    elif elem_type == \"css\":\n",
    "        try:\n",
    "            out = driver.find_element_by_css_selector(elem_text).is_displayed()\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            out = False\n",
    "    elif elem_type == 'tag':\n",
    "        try:\n",
    "            out = driver.find_element_by_tag_name(elem_text).is_displayed()\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            out = False\n",
    "    else:\n",
    "        raise ValueError(\"arg 'elem_type' must be either 'class' or 'css'\")\n",
    "    return(out)\n",
    "\n",
    "def _pause_for_captcha(driver):\n",
    "    while True:\n",
    "        time.sleep(30)\n",
    "        if not _is_element_displayed(driver, \"captcha-container\", \"class\"):\n",
    "            break\n",
    "\n",
    "def navigate_to_website(driver, site, data):\n",
    "    driver.get(site)\n",
    "    # Check to make sure a captcha page is not displayed.\n",
    "    check_for_captcha(driver, temp_data=data)\n",
    "\n",
    "def stripPKL(lis):\n",
    "    return([x.replace('.pkl', '') for x in lis])\n",
    "\n",
    "# Check to see if the page is currently stuck on a captcha page. If so, pause\n",
    "# the scraper until user has manually completed the captcha requirements.\n",
    "def check_for_captcha(driver, temp_data):\n",
    "    if _is_element_displayed(driver, \"captcha-container\", \"class\"):\n",
    "        save_Dictionary(obj=temp_data, name='TEMP')\n",
    "        print(\"\\nCAPTCHA!\\n\"\\\n",
    "              \"Manually complete the captcha requirements.\\n\"\\\n",
    "              \"Once that's done, if the program was in the middle of scraping \"\\\n",
    "              \"(and is still running), it should resume scraping after ~30 seconds.\")\n",
    "        _pause_for_captcha(driver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
